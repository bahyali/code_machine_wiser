import logging
from core.llm_interaction_service import LLMInteractionService
from services.schema_manager import DBSchemaManager # To use its formatting method
from core.config import settings

logger = logging.getLogger(__name__)

class SQLGenerationModule:
    def __init__(self):
        self.llm_service = LLMInteractionService() # Assuming LLMInteractionService is initialized here or injected
        self.schema_manager = DBSchemaManager() # Assuming DBSchemaManager is initialized here or injected

        # Load prompt templates
        try:
            with open("src/prompts/sql_generation_retrieval.txt", "r") as f:
                self.retrieval_prompt_template = f.read()
            with open("src/prompts/sql_generation_insight.txt", "r") as f:
                self.insight_prompt_template = f.read()
        except FileNotFoundError:
            logger.error("SQL generation prompt templates not found.")
            self.retrieval_prompt_template = "Generate a PostgreSQL SQL query for the request: {query}\n\nSchema:\n{schema}\n\nSQL:" # Fallback
            self.insight_prompt_template = "Generate a PostgreSQL SQL query to help derive insights for the request: {query}\n\nSchema:\n{schema}\nPrevious Results:\n{previous_results}\n\nSQL:" # Fallback

    async def generate_sql(self, intent: str, context: dict, request_id: str = None) -> str:
        """
        Generates an SQL query based on intent, user query, schema, and context.
        """
        user_query = context.get("user_query", "")
        schema_info = context.get("schema", {})
        previous_results = context.get("previous_results", [])

        formatted_schema = self.schema_manager.format_schema_for_llm(schema_info)

        if intent == "DATA_RETRIEVAL":
            prompt = self.retrieval_prompt_template.format(query=user_query, schema=formatted_schema)
            prompt_type = "sql_gen_retrieval"
        elif intent == "INSIGHTS":
            # Format previous results for the prompt (can be complex)
            formatted_results = "\n".join([f"Query: {res['query']}\nResults: {res['results']}" for res in previous_results])
            prompt = self.insight_prompt_template.format(query=user_query, schema=formatted_schema, previous_results=formatted_results)
            prompt_type = "sql_gen_insight"
        else:
            logger.error(f"Attempted to generate SQL for unsupported intent: {intent}", extra={'request_id': request_id, 'intent': intent})
            raise ValueError(f"Unsupported intent for SQL generation: {intent}")

        logger.debug(f"Generating SQL for intent: {intent}", extra={'request_id': request_id, 'intent': intent, 'prompt_type': prompt_type})

        try:
            llm_response = await self.llm_service.get_completion(prompt, prompt_type=prompt_type, request_id=request_id)

            # Basic parsing: expect SQL query in the response
            # LLM might wrap it in ```sql ... ``` or just return the query
            sql_query = llm_response.strip()
            if sql_query.startswith("```sql") and sql_query.endswith("```"):
                 sql_query = sql_query[len("```sql"): -len("```")].strip()
            elif sql_query.startswith("```") and sql_query.endswith("```"): # Handle generic code block
                 sql_query = sql_query[len("```"): -len("```")].strip()


            logger.info("SQL query generated by LLM", extra={'request_id': request_id, 'intent': intent, 'sql_query_truncated': sql_query[:settings.SQL_QUERY_LOG_MAX_LENGTH]})
            return sql_query

        except Exception as e:
            logger.error("Error during SQL generation", extra={'request_id': request_id, 'intent': intent, 'user_query': user_query, 'error': str(e)}, exc_info=True)
            raise # Re-raise for orchestrator to handle